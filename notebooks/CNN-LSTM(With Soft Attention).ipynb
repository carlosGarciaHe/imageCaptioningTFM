{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# CNN-LSTM (with soft attention) model\n\nThis notebook aims the construction, training and test of a CNN-LSTM model purposed in Vinyals et\nal. [15].\n\nThe CNN-LSTM model is a encoder-decoder designed for image caption generation."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Setup of libraries"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In the next cell we link the GPU hardware to tensorflow for use this component in the training process."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": "import csv # To read the captions of a csv\nimport tensorflow as tf # To build and train the ANN\nfrom tensorflow.keras.preprocessing.text import Tokenizer # To use the tokenizer to split the words\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences # \nimport numpy as np\nimport pickle\nfrom datetime import datetime\nimport time\nimport pandas as pd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tf.config.set_visible_devices([], 'GPU')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Data reading"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "First, we upload the descriptions of a CSV to a list and the image id to another list to build the path where the images are stored."
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": "def idToPath(id_image):\n    id_image = str(id_image)\n    complete_name=id_image+\".jpg\"\n    while len(complete_name)<16:\n        complete_name=\"0\"+complete_name\n    return \"data/train2017/\"+complete_name"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": "PATH = \"data/train_machine_spanish.xlsx\"\ndf = pd.read_excel(PATH, names=[\"id_image\",\"caption\"])\ndf['caption'] = df.apply(lambda x: \"smark \"+x['caption']+\" emark\", axis=1)\ndf['id_image'] = df.apply(lambda x: idToPath(x['id_image']),axis=1)"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": "PATH = \"data/validation.xlsx\"\nval_df = pd.read_excel(PATH, names=[\"id_image\",\"caption\"])\nval_df['caption'] = val_df.apply(lambda x: \"smark \"+x['caption']+\" emark\", axis=1)\nval_df['id_image'] = val_df.apply(lambda x: idToPath(x['id_image']),axis=1)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Setup of text data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We load the tokenizer that we initialized in word embeddings notebook."
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": "# loading\nwith open('items/tokenizer_spanish.pkl', 'rb') as handle:\n    tokenizer = pickle.load(handle)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We transform the descriptions into a list of integers that represent the index in the tokenizer's word index vocabulary."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": "sentences_x = tokenizer.texts_to_sequences(df['caption'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "And its equivalent for the labels that are the same lists with each element moved one position to the left"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": "sentences_y = [sentence[1:] for sentence in sentences_x]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We put pads on the right for every sentence that has less than 15 words."
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": "pad_sentences_x = pad_sequences(sentences_x, padding='post',maxlen=15)\npad_sentences_y = pad_sequences(sentences_y, padding='post',maxlen=15)"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([   2,    5,   55,    7,    1,  279,  230,    9, 2988,  450,    8,\n        139,    3,    0,    0], dtype=int32)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "pad_sentences_x[0]"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([   5,   55,    7,    1,  279,  230,    9, 2988,  450,    8,  139,\n          3,    0,    0,    0], dtype=int32)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "pad_sentences_y[0]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Model building\n\nThe embedding layer loaded from the model stored in word embeddings notebook. This model transform word indexes to embeddings for encoder inputs."
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": "EPOCHS = 100\nBATCH_SIZE=64"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": "class Embeddings_Model(tf.keras.Model):\n    \n    def __init__(self, max_length, embedding_dimension):\n        super(Embeddings_Model, self).__init__()\n        weights = None\n        # Load the weight of the layer embedding pre-trained\n        with open('items/embeddingLayerWeights_spanish.pkl', 'rb') as handle:\n            weights = pickle.load(handle)\n        self.embedding = tf.keras.layers.Embedding(max_length+1, embedding_dimension ,weights=[weights])\n        \n    def call(self, inputs):\n        x = self.embedding(inputs)\n        \n        return x"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": "class CNN_Model(tf.keras.Model):\n    \n    def __init__(self):\n        super(CNN_Model, self).__init__()\n        pre_trained_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet',\n                                                            input_shape=(224, 224, 3))\n        self.input_model = tf.keras.Sequential()\n        for layer in pre_trained_model.layers[:-1]:\n            self.input_model.add(layer)\n    def call(self, inputs):\n        x = self.input_model(inputs)\n        return x"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": "class AnnotationVectorInitializer(tf.keras.Model):\n    \n    def __init__(self, embedding_dimension):\n        super(AnnotationVectorInitializer, self).__init__()\n        self.flatten = tf.keras.layers.Flatten()\n        self.dense = tf.keras.layers.Dense(embedding_dimension, activation='tanh')\n    def call(self, inputs):\n        x = self.flatten(inputs)\n        x = self.dense(x)\n        return x"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": "class BahdanauAttention(tf.keras.Model):\n    def __init__(self, units):\n        super(BahdanauAttention, self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n\n    def call(self, features, hidden):\n        # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n\n        # hidden shape == (batch_size, hidden_size)\n        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n\n        # score shape == (batch_size, 64, hidden_size)\n        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n        \n        # attention_weights shape == (batch_size, 64, 1)\n        # you get 1 at the last axis because you are applying score to self.V\n        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n        # context_vector shape after sum == (batch_size, hidden_size)\n        context_vector = attention_weights * features\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector, attention_weights"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": "class LSTM_Model(tf.keras.Model):\n    \n    def __init__(self, max_length, embedding_dimension, num_result_words):\n        super(LSTM_Model, self).__init__()\n        self.embedding_dimension = embedding_dimension\n        self.lstm = tf.keras.layers.LSTM(embedding_dimension, input_shape=(num_result_words, embedding_dimension),\n                                         return_sequences=True,dropout=0.1, return_state=True,\n                                        recurrent_initializer='glorot_uniform')\n        self.output_model = tf.keras.layers.Dense(max_length)\n        self.flatten = tf.keras.layers.Flatten()\n        self.softAttention = BahdanauAttention(embedding_dimension)\n        \n    def call(self, captions, initial_state1, initial_state2, features):\n        #captions, initial_state, features = inputs[0],inputs[1], inputs[2]\n        captions = tf.reshape(captions, [-1,1,captions.shape[-1]])\n        features = tf.reshape(features,[-1,features.shape[-3]*features.shape[-2],512])\n        context_vector, attention_weights = self.softAttention(features, initial_state1)\n        z = tf.concat([tf.expand_dims(context_vector, 1), captions], axis=-1)\n        x, state1, state2 = self.lstm(z,initial_state=[initial_state1, initial_state2])\n        x = self.output_model(x)\n\n        return x, state1, state2, attention_weights"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_mean(loss_)"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": "class CNN_LSTM_Model():\n    \n    # This function declare every layer of the model\n    def __init__(self):        \n        # Number of differents words in the tokenizer vocabulary.\n        self.max_length = 14276\n        # Embedding dimension\n        self.embedding_dimension = 512\n        # Number of LSTM cells\n        self.cells=1024\n        # Maximum number or words that the model is able to generate in a caption.\n        self.num_result_words = 15\n        # Optimizer used\n        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n        # Initialize the encoder\n        self.encoder = CNN_Model()\n        # Initialize the embedding layer\n        self.embedding = Embeddings_Model(self.max_length, self.embedding_dimension)\n        # Initialize the decoder\n        self.decoder = LSTM_Model(self.max_length, self.cells, self.num_result_words)\n        # Initializers of hidden states\n        self.initializer1 = AnnotationVectorInitializer(self.cells)\n        self.initializer2 = AnnotationVectorInitializer(self.cells)\n    \n    # This function load all images for the encoder can transform them to image embeddings\n    # Parameters:\n    #            image_paths: Collection of path to images\n    #            load: Boolean that indicate if load all images or read a file with the embeddings\n    # Return:\n    #        A list with the image embeddings\n    def encoder_predict(self, image_paths, load=False, test=False):\n        predictions = []\n        contador=0\n        if load or test:\n            # If load=True then we need to predict all image embeddings with the encoder\n            # and stored for future uses\n            for image_path in image_paths:\n                # Visual indicator for longs process\n                if contador%1000==0:\n                    print(\"Procesando imagen\",contador)\n                contador+=1\n                # Read the file with tensorflow function\n                image = tf.io.read_file(image_path)\n                # Transform the image to jpeg in RGB color space\n                image = tf.image.decode_jpeg(image, channels=3)\n                # Resize to inception_v3 input size\n                image = tf.image.resize(image, (224, 224))\n                # Add a dimension to tensor for the model\n                image = np.expand_dims(image, axis=0)\n                # Add the result of the prediction to the list\n                predictions.append(self.encoder.predict(image))\n            # Store the image embeddings list\n            if not test:\n                with open('items/VGGimage_embeddings_list.pkl', 'wb') as handle:\n                    pickle.dump(predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n        else:\n            # Load the image embeddings list\n            with open('items/VGGimage_embeddings_list.pkl', 'rb') as handle:\n                predictions = pickle.load(handle)[:len(image_paths)]\n        \n        return predictions\n    \n    \n    # This function preprocess the data\n    # Parameters:\n    #           X_image: Image path list\n    #           X_caption: Caption list\n    #           Y_caption: Label caption list for compare with the predict caption\n    def preprocess_data(self,X_image,X_caption,Y_caption, test=False, load=False):\n        # Get the image embeddings\n        image_embeddings = np.array(self.encoder_predict(X_image,load=load,test=test))\n        \n        # Lambda function for map the word embeddings\n        map_embeddings = lambda x: self.embedding.predict(np.array([x]))\n        # Map the word embeddings\n        X_caption_embeddings = map_embeddings(X_caption)\n        \n        # A set of transforms in numpy array sizes\n        Y_caption_embeddings = np.array(Y_caption)\n        X_caption_embeddings = X_caption_embeddings.reshape((\n            -1, self.num_result_words, self.embedding_dimension))\n        Y_caption_embeddings = Y_caption_embeddings.reshape((\n            -1, self.num_result_words))\n        \n        return image_embeddings, X_caption_embeddings, Y_caption_embeddings\n    \n    \n    # This function train the model\n    # Parameters:\n    #           X_image: Image path list\n    #           X_caption: Caption list\n    #           Y_caption: Label caption list for compare with the predict caption\n    def train(self, X_image, X_caption, Y_caption):\n        loss = 0\n        \n        # We manually iterate the epochs\n        for epoch in range(EPOCHS):\n            # We build the batchs\n            for batch in range(0,X_image.shape[0],BATCH_SIZE):\n                image_embeddings_batch = None\n                X_caption_embedding_batch = None\n                Y_caption_embedding_batch = None\n                if batch+BATCH_SIZE>=len(X_image):\n                    image_embeddings_batch = X_image[batch:]\n                else:\n                    image_embeddings_batch = X_image[batch:batch+BATCH_SIZE]\n                if batch+BATCH_SIZE>=len(X_caption):\n                    X_caption_embedding_batch = X_caption[batch:]\n                else:\n                    X_caption_embedding_batch = X_caption[batch:batch+BATCH_SIZE]\n                if batch+BATCH_SIZE>=len(Y_caption):\n                    Y_caption_embedding_batch = Y_caption[batch:]\n                else:\n                    Y_caption_embedding_batch = Y_caption[batch:batch+BATCH_SIZE]\n                # We manually compute the gradients from the loss\n                # Reshape of the data\n                image_embeddings_batch, X_caption_embedding_batch, Y_caption_embedding_batch = self.preprocess_data(\n                    image_embeddings_batch,\n                    X_caption_embedding_batch,\n                    Y_caption_embedding_batch,\n                    test=True,\n                    load=False)\n                with tf.GradientTape() as tape:\n                    # Get the initial values of the hidden states\n                    state_t1 = self.initializer1(tf.reduce_mean(image_embeddings_batch, axis=-1))\n                    state_t2 = self.initializer2(tf.reduce_mean(image_embeddings_batch, axis=-1))\n                    loss = 0.\n                    # Each step computes the loss of error words in the sentences\n                    for step in range(0,X_caption_embedding_batch.shape[1]):\n                        token_t = X_caption_embedding_batch[:,:,step]\n                        output_t, state_t1,state_t2, attention_weights = self.decoder(\n                            token_t,\n                            state_t1,\n                            state_t2,\n                            image_embeddings_batch)\n                        loss += loss_function(Y_caption_embedding_batch[:,step],output_t[:,0])\n                if(batch%100*BATCH_SIZE==0):\n                    print(\"Epoch\",epoch,\"batch\",batch,\"Mean loss\",float(loss/X_caption_embedding_batch.shape[2]),\n                         datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S.%f)\"))\n                # Get the trainable weights\n                trainable_variables=self.decoder.trainable_variables+self.initializer1.trainable_variables+self.initializer2.trainable_variables\n                # Compute the gradients\n                gradients = tape.gradient(loss, trainable_variables)\n                # Apply gradients to trainable weights\n                self.optimizer.apply_gradients(zip(gradients, trainable_variables))\n                \n    # This function get the prediction by trained model\n    # Parameters:\n    #           X_image: Image path list\n    #           X_caption: Caption list\n    #           Y_caption: Label caption list for compare with the predict caption\n    def predict(self, X_image, X_caption, Y_caption):\n        \n        # Reshape of the data\n        image_embeddings, X_caption_embeddings, Y_caption_embeddings = self.preprocess_data(\n            X_image,\n            X_caption,\n            Y_caption,\n            test=True)\n        \n        images_list = []\n        captions_list = []\n        attention_list = []\n        for example in range(0,len(image_embeddings)):\n            tokens = []\n            at = []\n            input_token = tokenizer.word_index['smark']\n            hidden_state1 = self.initializer1(tf.reduce_mean(tf.expand_dims(image_embeddings[example], 0), axis=-1))\n            hidden_state2 = self.initializer2(tf.reduce_mean(tf.expand_dims(image_embeddings[example], 0), axis=-1))\n            while input_token != tokenizer.word_index['emark'] and len(tokens)<self.num_result_words:\n                tokens.append(input_token)\n                tokens_array = self.embedding.predict([input_token])\n                tokens_array = tf.expand_dims(tokens_array, 0)\n                output_t, hidden_state1, hidden_state2, attention_weights = self.decoder(\n                    tokens_array,\n                    hidden_state1,\n                    hidden_state2,\n                    image_embeddings[example])\n                input_token = np.argmax(output_t)\n                at.append(attention_weights)\n                \n            images_list.append(X_image[example])\n            captions_list.append(tokenizer.sequences_to_texts([tokens]))\n            attention_list.append(at)\n            if example%100==0:\n                print(\"%d images predicted\"%example)\n        \n        return images_list,captions_list,attention_list"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": "model = CNN_LSTM_Model()"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 0)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 0, 'Mean loss', 0.21451999247074127, '26-May-2020 (20:07:49.929571)')\n('Procesando imagen', 0)\n('batch', 64)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 128)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 192)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 256)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 320)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 384)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 448)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 512)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 576)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 640)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 704)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 768)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 832)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 896)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 960)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1024)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1088)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1152)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1216)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1280)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1344)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1408)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1472)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1536)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1600)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 1600, 'Mean loss', 0.131125807762146, '26-May-2020 (20:08:43.455544)')\n('Procesando imagen', 0)\n('batch', 1664)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1728)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1792)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1856)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1920)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 1984)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2048)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2112)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2176)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2240)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2304)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2368)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2432)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2496)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2560)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2624)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2688)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2752)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2816)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 2880)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 2944)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3008)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3072)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3136)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3200)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 3200, 'Mean loss', 0.12354955822229385, '26-May-2020 (20:09:36.703887)')\n('Procesando imagen', 0)\n('batch', 3264)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3328)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3392)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3456)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3520)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3584)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3648)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3712)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3776)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3840)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3904)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 3968)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4032)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4096)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4160)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4224)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4288)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4352)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4416)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4480)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4544)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4608)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4672)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4736)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4800)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 4800, 'Mean loss', 0.11879837512969971, '26-May-2020 (20:10:30.163788)')\n('Procesando imagen', 0)\n('batch', 4864)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4928)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 4992)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5056)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5120)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5184)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5248)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5312)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5376)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5440)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5504)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5568)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5632)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5696)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5760)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5824)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 5888)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 5952)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6016)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6080)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6144)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6208)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6272)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6336)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6400)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 6400, 'Mean loss', 0.11930398643016815, '26-May-2020 (20:11:23.915537)')\n('Procesando imagen', 0)\n('batch', 6464)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6528)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6592)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6656)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6720)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6784)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6848)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6912)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 6976)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7040)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7104)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7168)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7232)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7296)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7360)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7424)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7488)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7552)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7616)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7680)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7744)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7808)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7872)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 7936)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8000)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 8000, 'Mean loss', 0.12147574871778488, '26-May-2020 (20:12:18.383375)')\n('Procesando imagen', 0)\n('batch', 8064)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8128)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8192)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8256)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8320)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8384)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8448)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8512)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8576)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8640)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8704)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8768)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 8832)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8896)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 8960)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9024)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9088)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9152)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9216)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9280)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9344)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9408)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9472)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9536)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9600)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 9600, 'Mean loss', 0.11910853534936905, '26-May-2020 (20:13:12.891778)')\n('Procesando imagen', 0)\n('batch', 9664)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9728)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9792)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9856)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9920)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 9984)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10048)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10112)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10176)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10240)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10304)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10368)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10432)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10496)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10560)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10624)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10688)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10752)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10816)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10880)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 10944)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11008)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11072)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11136)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11200)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 11200, 'Mean loss', 0.11624602973461151, '26-May-2020 (20:14:07.332992)')\n('Procesando imagen', 0)\n('batch', 11264)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11328)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11392)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11456)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11520)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11584)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11648)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11712)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 11776)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11840)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11904)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 11968)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12032)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12096)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12160)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12224)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12288)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12352)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12416)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12480)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12544)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12608)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12672)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12736)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12800)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 12800, 'Mean loss', 0.11844060570001602, '26-May-2020 (20:15:02.008979)')\n('Procesando imagen', 0)\n('batch', 12864)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12928)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 12992)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13056)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13120)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13184)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13248)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13312)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13376)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13440)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13504)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13568)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13632)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13696)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13760)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13824)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13888)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 13952)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14016)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14080)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14144)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14208)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14272)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14336)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14400)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 14400, 'Mean loss', 0.11933824419975281, '26-May-2020 (20:15:56.657407)')\n('Procesando imagen', 0)\n('batch', 14464)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14528)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14592)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14656)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 14720)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14784)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14848)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14912)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 14976)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15040)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15104)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15168)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15232)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15296)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15360)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15424)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15488)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15552)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15616)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15680)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15744)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15808)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15872)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 15936)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16000)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 16000, 'Mean loss', 0.10508368164300919, '26-May-2020 (20:16:50.317166)')\n('Procesando imagen', 0)\n('batch', 16064)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16128)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16192)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16256)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16320)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16384)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16448)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16512)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16576)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16640)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16704)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16768)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16832)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16896)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 16960)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17024)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17088)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17152)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17216)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17280)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17344)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17408)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17472)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17536)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17600)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 17600, 'Mean loss', 0.1163657084107399, '26-May-2020 (20:17:44.618487)')\n('Procesando imagen', 0)\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('batch', 17664)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17728)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17792)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17856)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17920)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 17984)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18048)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18112)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18176)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18240)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18304)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18368)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18432)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18496)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18560)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18624)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18688)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18752)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18816)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18880)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 18944)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19008)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19072)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19136)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19200)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 19200, 'Mean loss', 0.10810302197933197, '26-May-2020 (20:18:39.086537)')\n('Procesando imagen', 0)\n('batch', 19264)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19328)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19392)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19456)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19520)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19584)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19648)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19712)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19776)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19840)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19904)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 19968)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20032)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20096)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20160)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20224)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20288)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20352)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20416)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20480)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20544)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20608)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 20672)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20736)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20800)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 20800, 'Mean loss', 0.10629589110612869, '26-May-2020 (20:19:33.662316)')\n('Procesando imagen', 0)\n('batch', 20864)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20928)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 20992)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21056)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21120)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21184)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21248)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21312)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21376)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21440)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21504)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21568)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21632)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21696)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21760)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21824)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21888)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 21952)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22016)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22080)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22144)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22208)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22272)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22336)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22400)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 22400, 'Mean loss', 0.11240841448307037, '26-May-2020 (20:20:27.548386)')\n('Procesando imagen', 0)\n('batch', 22464)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22528)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22592)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22656)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22720)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22784)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22848)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22912)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 22976)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23040)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23104)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23168)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23232)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23296)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23360)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23424)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23488)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23552)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 23616)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23680)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23744)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23808)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23872)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 23936)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24000)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 24000, 'Mean loss', 0.10125274956226349, '26-May-2020 (20:21:21.970767)')\n('Procesando imagen', 0)\n('batch', 24064)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24128)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24192)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24256)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24320)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24384)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24448)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24512)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24576)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24640)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24704)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24768)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24832)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24896)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 24960)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25024)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25088)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25152)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25216)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25280)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25344)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25408)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25472)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25536)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25600)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 25600, 'Mean loss', 0.10873205959796906, '26-May-2020 (20:22:16.324905)')\n('Procesando imagen', 0)\n('batch', 25664)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25728)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25792)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25856)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25920)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 25984)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26048)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26112)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26176)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26240)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26304)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26368)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26432)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26496)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 26560)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26624)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26688)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26752)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26816)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26880)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 26944)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27008)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27072)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27136)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27200)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 27200, 'Mean loss', 0.10795005410909653, '26-May-2020 (20:23:10.811175)')\n('Procesando imagen', 0)\n('batch', 27264)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27328)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27392)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27456)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27520)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27584)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27648)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27712)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27776)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27840)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27904)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 27968)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28032)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28096)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28160)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28224)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28288)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28352)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28416)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28480)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28544)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28608)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28672)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28736)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28800)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 28800, 'Mean loss', 0.10679571330547333, '26-May-2020 (20:24:05.258970)')\n('Procesando imagen', 0)\n('batch', 28864)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28928)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 28992)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29056)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29120)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29184)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29248)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29312)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29376)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29440)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 29504)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29568)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29632)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29696)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29760)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29824)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29888)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 29952)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30016)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30080)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30144)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30208)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30272)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30336)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30400)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 30400, 'Mean loss', 0.10138795524835587, '26-May-2020 (20:24:59.734492)')\n('Procesando imagen', 0)\n('batch', 30464)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30528)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30592)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30656)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30720)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30784)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30848)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30912)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 30976)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31040)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31104)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31168)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31232)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31296)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31360)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31424)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31488)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31552)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31616)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31680)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31744)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31808)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31872)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 31936)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32000)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 32000, 'Mean loss', 0.1069454625248909, '26-May-2020 (20:25:54.254301)')\n('Procesando imagen', 0)\n('batch', 32064)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32128)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32192)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32256)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32320)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32384)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 32448)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32512)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32576)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32640)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32704)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32768)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32832)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32896)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 32960)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33024)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33088)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33152)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33216)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33280)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33344)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33408)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33472)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33536)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33600)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 33600, 'Mean loss', 0.10536739975214005, '26-May-2020 (20:26:48.963068)')\n('Procesando imagen', 0)\n('batch', 33664)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33728)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33792)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33856)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33920)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 33984)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34048)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34112)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34176)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34240)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34304)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34368)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34432)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34496)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34560)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34624)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34688)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34752)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34816)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34880)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 34944)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35008)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35072)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35136)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35200)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 35200, 'Mean loss', 0.10829192399978638, '26-May-2020 (20:27:43.371240)')\n('Procesando imagen', 0)\n('batch', 35264)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35328)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 35392)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35456)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35520)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35584)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35648)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35712)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35776)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35840)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35904)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 35968)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36032)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36096)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36160)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36224)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36288)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36352)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36416)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36480)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36544)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36608)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36672)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36736)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36800)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 36800, 'Mean loss', 0.10423947870731354, '26-May-2020 (20:28:37.660326)')\n('Procesando imagen', 0)\n('batch', 36864)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36928)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 36992)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37056)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37120)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37184)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37248)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37312)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37376)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37440)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37504)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37568)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37632)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37696)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37760)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37824)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37888)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 37952)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38016)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38080)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38144)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38208)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38272)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('batch', 38336)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38400)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 38400, 'Mean loss', 0.10676458477973938, '26-May-2020 (20:29:32.300943)')\n('Procesando imagen', 0)\n('batch', 38464)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38528)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38592)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38656)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38720)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38784)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38848)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38912)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 38976)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39040)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39104)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39168)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39232)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39296)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39360)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39424)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39488)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39552)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39616)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39680)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39744)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39808)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39872)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 39936)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40000)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 40000, 'Mean loss', 0.1056944727897644, '26-May-2020 (20:30:26.603804)')\n('Procesando imagen', 0)\n('batch', 40064)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40128)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40192)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40256)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40320)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40384)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40448)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40512)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40576)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40640)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40704)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40768)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40832)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40896)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 40960)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41024)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41088)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41152)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41216)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('batch', 41280)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41344)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41408)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41472)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41536)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41600)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Epoch', 0, 'batch', 41600, 'Mean loss', 0.10055594146251678, '26-May-2020 (20:31:21.339158)')\n('Procesando imagen', 0)\n('batch', 41664)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41728)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41792)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41856)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41920)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 41984)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42048)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42112)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42176)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42240)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42304)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42368)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42432)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42496)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42560)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42624)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42688)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42752)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42816)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42880)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 42944)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 43008)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 43072)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n('batch', 43136)\n('X_caption_embedding_batch', (64, 15, 512))\n('Y_caption_embedding_batch', (64, 15))\n('image_embeddings_batch', (64, 1, 14, 14, 512))\n('Procesando imagen', 0)\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-756750d0da54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_sentences_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_sentences_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-e49391caeeb4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_image, X_caption, Y_caption)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mY_caption_embedding_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     load=False)\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_caption_embedding_batch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_caption_embedding_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-e49391caeeb4>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(self, X_image, X_caption, Y_caption, test, load)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_caption\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_caption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Get the image embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mimage_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Lambda function for map the word embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-e49391caeeb4>\u001b[0m in \u001b[0;36mencoder_predict\u001b[0;34m(self, image_paths, load, test)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# Add the result of the prediction to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Store the image embeddings list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.pyc\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m           model, mode)\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m       callbacks = cbks.configure_callbacks(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m     if (context.executing_eagerly()\n\u001b[1;32m    417\u001b[0m         or ops.get_default_graph()._building_function):  # pylint: disable=protected-access\n\u001b[0;32m--> 418\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/data/ops/iterator_ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    592\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/data/ops/iterator_ops.pyc\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    617\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 619\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gen_dataset_ops.pyc\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2694\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   2695\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MakeIterator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2696\u001b[0;31m         tld.op_callbacks, dataset, iterator)\n\u001b[0m\u001b[1;32m   2697\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": "model.train(df['id_image'], pad_sentences_x, pad_sentences_y)"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": "PATH = \"data/validation.xlsx\"\ndf_test = pd.read_excel(PATH, names=[\"id_image\",\"caption\"])\ndf_test['caption'] = df_test.apply(lambda x: \"smark \"+x['caption']+\" emark\", axis=1)\ndf_test['id_image'] = df_test.apply(lambda x: idToPath(x['id_image']),axis=1)"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": "test_sentences_x = tokenizer.texts_to_sequences(df_test['caption'])"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": "test_sentences_y = [sentence[1:] for sentence in test_sentences_x]"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": "test_pad_sentences_x = pad_sequences(test_sentences_x, padding='post',maxlen=15)\ntest_pad_sentences_y = pad_sequences(test_sentences_y, padding='post',maxlen=15)"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Procesando imagen', 0)\n('Procesando imagen', 1000)\n('Procesando imagen', 2000)\n('Procesando imagen', 3000)\n('Procesando imagen', 4000)\n0 images predicted\n100 images predicted\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a14e943a7b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pad_sentences_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pad_sentences_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-669abd91d0dc>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_image, X_caption, Y_caption)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0minput_token\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emark'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_result_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0mtokens_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0mtokens_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 output_t, hidden_state1, hidden_state2, attention_weights = self.decoder(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.pyc\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.pyc\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.pyc\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/def_function.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0;31m# V2 control flow relies on XLAControlFlowContext to generate a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/def_function.pyc\u001b[0m in \u001b[0;36m_get_tracing_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_count\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_count\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": "img, captions, attentions = model.predict(df_test['id_image'], test_pad_sentences_x, test_pad_sentences_y)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "for i in range(len(img)):\n    print(img[i])\n    print(captions[i])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "result_df = pd.DataFrame(columns=[\"id_image\",\"caption\"])\nfor i in range(len(img)):\n    image = img[i][:-4].split('/')[-1]\n    caption = captions[i][0][6:]\n    result_df.loc[i] = [image,caption]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "result_df.to_csv(\"results/val_M019_I.csv\", encoding = 'utf-8',index=False)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Implementacion del modelo"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class CNN_LSTM_Model():\n    \n    def __init__(self):        \n        self.max_length = 4028\n        self.embedding_dimension = 512\n        self.cells=1024\n        self.num_result_words = 15\n        \n        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n        \n        self.encoder = CNN_Model(self.embedding_dimension)\n        self.embedding = Embeddings_Model(self.max_length, self.embedding_dimension)\n        self.decoder = LSTM_Model(self.max_length, self.cells, self.num_result_words)\n        \n        self.initializer1 = AnnotationVectorInitializer(self.cells)\n        self.initializer2 = AnnotationVectorInitializer(self.cells)\n    \n    # Esta funcion recibe un batch de imagenes que pre-procesa y alimenta a la GoogleNet.\n    # La salida es el batch correspondiente a sus image embeddings.\n    def encoder_predict(self, image_paths):\n        predictions = []\n        contador=0\n        for image_path in image_paths:\n            if contador%1000==0:\n                print(\"Procesando imagen\",contador,\n                     datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S.%f)\"))\n            contador+=1\n            image = tf.io.read_file(image_path)\n            image = tf.image.decode_jpeg(image, channels=3)\n            image = tf.image.resize(image, (224, 224))\n            #image = tf.keras.applications.VGG16.preprocess_input(image)\n            image = np.expand_dims(image, axis=0)\n            predictions.append(self.encoder.predict(image))\n        \n        return predictions\n    \n    # This function preprocess the data\n    # Parameters:\n    #           X_image: Image path list\n    #           X_caption: Caption list\n    #           Y_caption: Label caption list for compare with the predict caption\n    def preprocess_data(self,X_image,X_caption,Y_caption, test=False):\n        # Get the image embeddings\n        image_embeddings = np.array(self.encoder_predict(X_image, test))\n        \n        # Lambda function for map the word embeddings\n        map_embeddings = lambda x: self.embedding.predict(np.array([x]))\n        # Map the word embeddings\n        X_caption_embeddings = map_embeddings(X_caption)\n        \n        # A set of transforms in numpy array sizes\n        Y_caption_embeddings = np.array(Y_caption)\n        X_caption_embeddings = X_caption_embeddings.reshape((\n            -1, self.num_result_words, self.embedding_dimension))\n        Y_caption_embeddings = Y_caption_embeddings.reshape((\n            -1, self.num_result_words))\n        \n        return image_embeddings, X_caption_embeddings, Y_caption_embeddings\n    \n    # This function train the model\n    # Parameters:\n    #           X_image: Image path list\n    #           X_caption: Caption list\n    #           Y_caption: Label caption list for compare with the predict caption\n    def train(self, X_image, X_caption, Y_caption):\n        loss = 0\n        \n        # Reshape of the data\n        image_embeddings, X_caption_embeddings, Y_caption_embeddings = self.preprocess_data(\n            X_image,\n            X_caption,\n            Y_caption,\n            False)\n        \n        split_threshold = int(len(X_image)*-0.1)\n        \n        # We manually iterate the epochs\n        for epoch in range(EPOCHS):\n            # We build the batchs\n            for batch in range(0,image_embeddings[:split_threshold].shape[0],BATCH_SIZE):\n                image_embeddings_batch = None\n                X_caption_embedding_batch = None\n                Y_caption_embedding_batch = None\n                if batch+BATCH_SIZE>=len(image_embeddings[:split_threshold]):\n                    image_embeddings_batch = image_embeddings[:split_threshold][batch:]\n                else:\n                    image_embeddings_batch = image_embeddings[:split_threshold][batch:batch+BATCH_SIZE]\n                if batch+BATCH_SIZE>=len(X_caption_embeddings[0][:split_threshold]):\n                    X_caption_embedding_batch = X_caption_embeddings[:,:split_threshold][:,batch:]\n                else:\n                    X_caption_embedding_batch = X_caption_embeddings[:,:split_threshold][:,batch:batch+BATCH_SIZE]\n                if batch+BATCH_SIZE>=len(Y_caption_embeddings[:split_threshold]):\n                    Y_caption_embedding_batch = Y_caption_embeddings[:split_threshold][batch:]\n                else:\n                    Y_caption_embedding_batch = Y_caption_embeddings[:split_threshold][batch:batch+BATCH_SIZE]\n                # We manually compute the gradients from the loss\n                with tf.GradientTape() as tape:\n                    # Get the initial values of the hidden states\n                    state_t1 = self.initializer1(tf.reduce_mean(image_embeddings_batch, axis=-1))\n                    state_t2 = self.initializer2(tf.reduce_mean(image_embeddings_batch, axis=-1))\n                    loss = 0.\n                    # Each step computes the loss of error words in the sentences\n                    for step in range(0,X_caption_embedding_batch.shape[2]):\n                        token_t = X_caption_embedding_batch[:,:,step]\n                        output_t, state_t1,state_t2, attention_weights = self.decoder(\n                            token_t,state_t1,state_t2,image_embeddings_batch)\n                        loss += loss_function(Y_caption_embedding_batch[:,step],output_t[:,0])\n                if(batch%100*BATCH_SIZE==0):\n                    print(\"Epoch\",epoch,\"batch\",batch,\"Mean loss\",float(loss/X_caption_embedding_batch.shape[2]),\n                         datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S.%f)\"))\n                # Get the trainable weights\n                trainable_variables=self.decoder.trainable_variables+self.initializer1.trainable_variables+self.initializer2.trainable_variables\n                # Compute the gradients\n                gradients = tape.gradient(loss, trainable_variables)\n                # Apply gradients to trainable weights\n                self.optimizer.apply_gradients(zip(gradients, trainable_variables))\n            \n\n        images_list = []\n        captions_list = []\n        attention_list = []\n        image_val = image_embeddings[split_threshold:]\n        for example in range(len(image_val)):\n            tokens = []\n            at = []\n            input_token = tokenizer.word_index['smark']\n            hidden_state1 = self.initializer1(tf.reduce_mean(tf.expand_dims(image_val[example], 0), axis=-1))\n            hidden_state2 = self.initializer2(tf.reduce_mean(tf.expand_dims(image_val[example], 0), axis=-1))\n            while input_token != tokenizer.word_index['emark'] and len(tokens)<self.num_result_words:\n                tokens.append(input_token)\n                tokens_array = map_embeddings([input_token])\n                tokens_array = tf.expand_dims(tokens_array, 0)\n                #tokens_array = tokens_array.reshape((1, -1, self.embedding_dimension))\n                output_t, hidden_state1, hidden_state2, attention_weights = self.decoder(tokens_array,hidden_state1,hidden_state2,image_val[example])\n                input_token = np.argmax(output_t)\n                at.append(attention_weights)\n            images_list.append(X_image[split_threshold:][example])\n            captions_list.append(tokenizer.sequences_to_texts([tokens]))\n            attention_list.append(at)\n        \n        return images_list,captions_list,attention_list"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class AnnotationVectorInitializer(tf.keras.Model):\n    \n    def __init__(self, embedding_dimension):\n        super(AnnotationVectorInitializer, self).__init__()\n        self.flatten = tf.keras.layers.Flatten()\n        self.dense = tf.keras.layers.Dense(embedding_dimension, activation='tanh')\n    def call(self, inputs):\n        x = self.flatten(inputs)\n        x = self.dense(x)\n        return x"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class CNN_Model(tf.keras.Model):\n    \n    def __init__(self, embedding_dimension):\n        super(CNN_Model, self).__init__()\n        pre_trained_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet',\n                                                            input_shape=(224, 224, 3))\n        self.input_model = tf.keras.Sequential()\n        for layer in pre_trained_model.layers[:-1]:\n            self.input_model.add(layer)\n    def call(self, inputs):\n        x = self.input_model(inputs)\n        return x"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class BahdanauAttention(tf.keras.Model):\n    def __init__(self, units):\n        super(BahdanauAttention, self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n\n    def call(self, features, hidden):\n        # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n\n        # hidden shape == (batch_size, hidden_size)\n        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n\n        # score shape == (batch_size, 64, hidden_size)\n        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n        \n        # attention_weights shape == (batch_size, 64, 1)\n        # you get 1 at the last axis because you are applying score to self.V\n        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n        # context_vector shape after sum == (batch_size, hidden_size)\n        context_vector = attention_weights * features\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector, attention_weights"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class LSTM_Model(tf.keras.Model):\n    \n    def __init__(self, max_length, embedding_dimension, num_result_words):\n        super(LSTM_Model, self).__init__()\n        self.embedding_dimension = embedding_dimension\n        self.lstm = tf.keras.layers.LSTM(embedding_dimension, input_shape=(num_result_words, embedding_dimension),\n                                         return_sequences=True,dropout=0.1, return_state=True,\n                                        recurrent_initializer='glorot_uniform')\n        self.output_model = tf.keras.layers.Dense(max_length)\n        self.flatten = tf.keras.layers.Flatten()\n        self.softAttention = BahdanauAttention(embedding_dimension)\n        \n    def call(self, captions, initial_state1, initial_state2, features):\n        #captions, initial_state, features = inputs[0],inputs[1], inputs[2]\n        captions = tf.reshape(captions, [-1,1,captions.shape[-1]])\n        features = tf.reshape(features,[-1,features.shape[-3]*features.shape[-2],512])\n        context_vector, attention_weights = self.softAttention(features, initial_state1)\n        z = tf.concat([tf.expand_dims(context_vector, 1), captions], axis=-1)\n        x, state1, state2 = self.lstm(z,initial_state=[initial_state1, initial_state2])\n        x = self.output_model(x)\n\n        return x, state1, state2, attention_weights"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class Embeddings_Model(tf.keras.Model):\n    \n    def __init__(self, max_length, embedding_dimension):\n        super(Embeddings_Model, self).__init__()\n        weights = None\n        with open('embeddingLayerWeights512.pkl', 'rb') as handle:\n            weights = pickle.load(handle)\n        self.embedding = tf.keras.layers.Embedding(max_length+1, embedding_dimension ,weights=[weights])\n        \n    def call(self, inputs):\n        x = self.embedding(inputs)\n        \n        return x"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def sparse_cross_entropy(y_true, y_pred):\n    \"\"\"\n    Calculate the cross-entropy loss between y_true and y_pred.\n    \n    y_true is a 2-rank tensor with the desired output.\n    The shape is [batch_size, sequence_length] and it\n    contains sequences of integer-tokens.\n\n    y_pred is the decoder's output which is a 3-rank tensor\n    with shape [batch_size, sequence_length, num_words]\n    so that for each sequence in the batch there is a one-hot\n    encoded array of length num_words.\n    \"\"\"\n    #y_true = tf.reshape(y_true, [-1,15])\n    y_true = tf.dtypes.cast(y_true, tf.int32)\n    # Calculate the loss. This outputs a\n    # 2-rank tensor of shape [batch_size, sequence_length]\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true,\n                                                          logits=y_pred)\n    \n    # Keras may reduce this across the first axis (the batch)\n    # but the semantics are unclear, so to be sure we use\n    # the loss across the entire 2-rank tensor, we reduce it\n    # to a single scalar with the mean function.\n    loss_mean = tf.reduce_mean(loss)\n    return loss_mean"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_mean(loss_)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model = CNN_LSTM_Model()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "len(pad_sentences_y)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "img, captions, attentions = model.train_on_batch(path_dataset[:9000], pad_sentences_x[:9000], pad_sentences_y[:9000])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "for i in range(len(img)):\n    print(img[i])\n    print(captions[i])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install Pillow"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from PIL import Image\nimport matplotlib.pyplot as plt"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "attention_plot = np.zeros((15, 196))\n\nprint(len(attentions[0][0]))\n\nattention_plot = attention_plot[:len(result), :]\nlen_result = len(img)\nfor i in range(len(img)): \n    temp_image = np.array(Image.open(image))\n\n    fig = plt.figure(figsize=(10, 10))\n    for l in range(len_result):\n        temp_att = np.resize(attention_plot[l], (14, 14))\n        ax = fig.add_subplot(len_result//2, len_result//2, l+1)\n        ax.set_title(result[l])\n        img = ax.imshow(temp_image)\n        ax.imshow(temp_att, cmap='gray', alpha=0.6, extent=img.get_extent())\n\n    plt.tight_layout()\n    plt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "self.embedding.predict(np.array([1]))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#contador = len(path_dataset)-len(predictions)\n#print(contador)\nfor caption in predictions:\n    index_list = []\n    for token in caption:\n        index_list.append(np.argmax(token))\n    tokens_list = tokenizer.sequences_to_texts([index_list])\n    print(path_dataset[contador])\n    print(tokens_list)\n    contador+=1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# This variable adjusts the maximum length of the vocabulary\n# If the number is less than the actual length, we remove the least used words\nmax_length = 4028\n# This variable adjust the dimensions of the embeddings. A high value may represent more complex embeddings\n# but the artificial neural network will be larger.\nembedding_dimension=1000\n\nnum_words = 42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Para el encoder vamos a usar los embeddings previamente creados de las imagenes, los cuales anadimos al modelo mediante una fully connected. La salida sera el estado inicial que reciba el decoder."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "encoder_input = tf.keras.layers.Input(shape=(embedding_dimension, ))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "encoder = tf.keras.layers.Dense(embedding_dimension,\n                             activation='tanh')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "num_batches = (len(image_embeddings)/32)\nh0 = []\nprint(num_batches)\nfor i in range(len(image_embeddings)):\n    h0.append(np.array(image_embeddings[i]))\nh0 = np.array(h0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Para el decoder tendremos una capa embedding previamente entrenada que transformara los integers a embeddings. Estos se introducen en el input de la LSTM."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "decoder_input = tf.keras.layers.Input(shape=(None, ))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "embedding_layer = tf.keras.layers.Embedding(max_length+1, embedding_dimension)\nembedding_layer_weights = None\n# loading\nwith open('embeddingLayerWeights.pkl', 'rb') as handle:\n    embedding_layer_weights = pickle.load(handle)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "lstm = tf.keras.layers.LSTM(42)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "dense_layer = tf.keras.layers.Dense(len(tokenizer.word_index),\n                             activation='tanh')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "decoder_output = dense_layer(lstm(embedding_layer(decoder_input), initial_state=encoder(h0)))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model = tf.keras.Model(inputs=[encoder_input, decoder_input],\n                      outputs=[decoder_output])"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
